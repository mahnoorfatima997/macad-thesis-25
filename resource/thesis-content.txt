INITIAL BRIEF IDEAS FOR THESIS AND APP 
In current architecture programs, students increasingly utilize AI for design ideation, analysis, and even drafting reports. Without guidance, this can devolve into cognitive offloading – e.g. blindly accepting an AI-generated design proposal (“AI Twin”) without the creative struggle and critical evaluation that nurture expertise. A recent survey indicates 74% of new architecture graduates do not feel confident in their independent design skills, and rapid AI adoption in practice (41% of firms in 2024 to 59% in 2025) has outpaced the development of pedagogical frameworks to integrate AI constructively. There is an urgent need for an educational approach that harnesses AI’s benefits without inducing “cognitive bankruptcy.” This Master’s thesis addresses that need by proposing a multimodal AI mentor tool for architecture education, designed to reduce cognitive offloading and actively enhance students’ cognitive development. By engaging students in Socratic dialogue, contextual reasoning, and rich multimodal interaction (text, sketches, diagrams), the AI mentor aims to function as a scaffold rather than a crutch – guiding learners through challenges and reinforcing critical thinking, instead of simply providing answers.




In summary, this thesis will develop, deploy, and evaluate an AI-driven mentorship platform (“ArchMentor”) that interacts through both natural language and visual media (drawings, design sketches) to coach architecture students. The work will be structured in three phases: (1) System Development – building the AI mentor (architecture, model, interface) and ensuring it embodies cognitive enhancement principles; (2) Benchmarking and Evaluation Design – establishing rigorous methods to compare the mentor’s performance and cognitive impact against other AI tools (GPT-4, Claude, etc.), informed by academic benchmarking standards; and (3) User Testing and Analysis – conducting a controlled study with student participants to measure learning outcomes, cognitive engagement, and user experience. The end goal is to produce a validated prototype and a comprehensive evaluation that not only serve as a Master’s thesis but are suitable for academic publication and future research. Figure 1 illustrates the overall strategy, showing how the project components (development, benchmarking, user study) flow into one another and contribute to the thesis objectives (a visual strategy roadmap is recommended here).


Building the ArchMentor system will require a combination of AI model integration, multimodal interface design, and robust infrastructure to support real-time mentoring interactions. We outline two complementary development approaches: (a) leveraging existing Large Language Model (LLM) APIs (e.g. OpenAI GPT-4/GPT-5, Anthropic Claude, Google Gemini, Meta LLaMA 2) to rapidly prototype the mentor’s conversational abilities; and (b) developing custom AI agents from scratch or via fine-tuning to tailor the mentor’s behavior and incorporate domain-specific knowledge. Both approaches will be considered to balance development speed with control and academic rigor.
At its core, the AI mentor tool will follow a client-server architecture with modular components. On the backend, a Language Reasoning Module (powered by an LLM) will handle natural language understanding and generation. A Knowledge Base (domain-specific content such as architectural design principles, case studies, building codes) may be integrated, enabling the agent to retrieve facts or examples to enrich its guidance. A Vision Module will enable multimodal interaction – for instance, using a computer vision model to analyze student-uploaded sketches or diagrams of building designs. These components will be orchestrated by a Mentor Orchestration Layer that maintains context (student’s current task, skill level, progress) and enforces the Socratic tutoring strategy (deciding when to ask a guiding question versus when to provide an explanation or hint). On the client side, a user interface will allow students to chat with the mentor (via text or voice) and share visual content. This could be a web application or a dedicated app, providing text chat, image upload, and possibly a whiteboard or sketch pad. The system will also include logging and analytics subsystems to capture interaction data for research (with appropriate consent and privacy measures). Figure 2 sketches the proposed system architecture, including the data flows between the user, interface, AI models, and data storage.
We plan to utilize state-of-the-art APIs and frameworks to implement the above architecture. For rapid prototyping with existing models, APIs such as OpenAI’s or Anthropic’s can be used to power the Language Module (ensuring the model is capable of multi-turn dialogue and instruction following). If those are insufficient for multimodal needs, emerging multimodal models like GPT-4Vision or Google’s Gemini (which reportedly can process images) could be leveraged when available. Alternatively, open-source frameworks like HuggingFace Transformers can be employed to fine-tune a domain-specific LLM on architectural content, ensuring the model is familiar with architecture terminology and history. For the Vision Module, we can incorporate image recognition or captioning models (e.g. CLIP or a specialized CNN) to parse student sketches – for example, identifying architectural elements in an image or generating a textual description of a floor plan. The Orchestration Layer logic can be implemented with agent frameworks such as LangChain (which allows chaining LLM calls with conditionals) or custom Python code that uses the LLM’s outputs to decide next steps. The UI could be built as a web app using React (for flexibility) or a simpler notebook/interface for initial testing. We will also integrate relevant APIs for ancillary functions: e.g., using speech-to-text and text-to-speech if voice interaction is desired, or graphics libraries for drawing feedback. The deployment can initially run on a cloud server or local machine with GPU support for model inference; containerization (Docker) is recommended for reproducibility.
The project will start with a minimal viable prototype using a high-level API (for example, a GPT-4 based chatbot with a basic interface) to validate the concept of Socratic guidance in design problems. This prototype will then be iteratively refined – adding the knowledge base, incorporating visual inputs, and tuning the conversational style based on small pilot tests. During development, we’ll maintain two parallel tracks: one focusing on algorithm/model development (ensuring the AI’s outputs align with pedagogical goals) and another on infrastructure and data, i.e. setting up databases to log interactions, ensuring we can collect metrics on user behavior and performance. By the end of the development phase, the tool should be capable of engaging a student with an architectural design challenge (e.g. “redesign this space into a community center”) and providing an interactive experience where the student is prompted to think aloud, consider alternatives, and only gradually receive tailored insights or hints from the AI mentor – as opposed to a direct solution.
Develop the system architecture (as summarized above) and choose technologies for each component. Decide whether to use a third-party LLM via API or a custom model – weighing factors like development time, cost (API usage vs training), and control over model behavior. Select or prepare the domain knowledge base: e.g., compile a corpus of architecture case studies, design critiques, building science facts that the mentor can draw on. If multimodal support is needed, choose an approach for image analysis (pre-trained model or simple feature extraction). Output: an architecture diagram (as 
Begin by implementing a basic text-based conversational agent. Using an LLM API (like GPT-4) for speed, create a backend that echoes user queries to the model along with a predefined “mentor persona” prompt. This persona prompt will instruct the LLM to behave as a thoughtful architecture tutor (e.g., “You are an AI architecture mentor. Never directly give the full solution; instead ask guiding questions, encourage reflection, and reference architecture principles in explanations.”). Develop a simple front-end (could be a Jupyter notebook or web form) to test the conversation flow. Evaluate qualitatively whether the model’s responses align with the desired Socratic style. Adjust the prompt or few-shot examples until the baseline conversational behavior is satisfactory.recommended in Figure 2) and a tech stack list (programming language, libraries, models, etc.).
Extend the agent with architecture-specific knowledge. For instance, implement a retrieval mechanism where relevant content from the knowledge base is fetched (based on the user’s query) and fed into the model’s context. This can be achieved with an embedding-based semantic search (using tools like FAISS or Elasticsearch over the knowledge documents) or by fine-tuning the model on a dataset of architecture Q&A. The goal is to ensure the mentor provides accurate and contextually rich information (e.g., citing a known architectural case when relevant) to support its guidance. Test that the agent can correctly incorporate this knowledge in answers (for example, if a student asks about sustainable materials, the mentor can draw from the knowledge base on green architecture). Output: A refined agent backend that combines LLM responses with knowledge base lookups (a working “retrieval-augmented generation” pipeline).
Enable the system to accept and process visual inputs. At this step, implement the Vision Module: allow the user to upload an image of a sketch or model. For simplicity, if advanced image understanding is challenging, the system could prompt the user to describe their sketch in text, but ideally we will attempt some automation (e.g., using a pre-trained image captioning model or a custom classifier to detect elements like “doors”, “windows”, “layout style”). The mentor can then comment on or ask about the design. For example, if a floor plan image is provided, the system might identify key components or at least provide a structured way for the user to mark regions of interest. Output: Multimodal input handling integrated into the interface and backend (with at least rudimentary image analysis). At this stage, also update the persona instructions for the LLM so that it knows to incorporate references to the visual context (for instance, instruct the model: “If the user provided an image of a design, first discuss elements visible or ask clarifying questions about the image.”).
Develop the orchestration logic that truly differentiates this mentor from a standard QA chatbot. This may involve creating a dialogue policy – a set of rules or an algorithm that determines how the AI responds at each turn. For instance, the policy might be: If the student asks a direct question that is factual and simple, the mentor gives the answer (with a brief explanation). If the student asks a complex design question, the mentor responds with a question or hint to encourage thinking. We may implement this via prompt engineering (having the LLM self-classify the query type and respond accordingly) or with an external decision module (a small program that intercepts the conversation, possibly using the LLM in a reasoning mode to decide the next action). Another aspect is maintaining contextual awareness: the mentor should remember past interactions in the session (using conversation history) and possibly the student’s past performance (from logs) to tailor responses. For example, if the student has repeatedly struggled with a concept, the mentor will adapt by providing more structured guidance or revisiting fundamentals. Output: A fully functional conversational logic that encapsulates the mentor’s pedagogical strategy (Socratic method, adaptive feedback). At this point, one could produce a flowchart of the dialogue policy as internal documentation or a figure in the thesis.
Implement mechanisms to gather feedback within the interaction. This might include explicit checks (the mentor asking “Does this make sense to you? Can you explain why we chose this solution?” to gauge the student’s understanding) and implicit signals (tracking response times, or whether the student eventually arrives at a correct solution). Use these to adjust the mentor’s approach in real-time. Additionally, create a simple user model that is updated as the student progresses – e.g., a profile that stores which concepts the student has mastered or where they needed many hints. While a full cognitive user model is complex, even a rudimentary tracking of solved tasks or errors can inform future sessions. Output: The mentor system now has a rudimentary adaptive capability, closing the loop between student performance and AI guidance strategy.
Develop a more polished user interface suitable for a study deployment. This could involve a chat interface with rich text (for formulas or references), an image pane for any visual content, and possibly additional tools like a scratchpad for the student’s notes. Ensure the UI is intuitive for students to use during an architectural problem-solving session. If feasible, integrate support for voice input/output to mimic a natural studio critic (though text is the primary mode for now). Also, incorporate a session recording feature where all interactions (and possibly screenshots of the design at various stages) are saved for analysis (with consent).
Before formal evaluation, perform internal testing. This can include unit tests for components (e.g. does the image analysis return expected descriptors?) and scenario tests where team members role-play as students to see how the mentor responds. Identify failure modes (for example, does the mentor ever give away the full answer too early? Does it ever hallucinate architectural facts incorrectly?). Refine the prompts, rules, or model choice as needed. It’s likely we will iterate on steps 4–7 multiple times as we fine-tune the mentor’s balance between helpfulness and cognitive challenge.










Contextual Reasoning agent
This component of the agent maintains an understanding of the context – including the problem at hand and the student’s current state. It can be thought of as the agent’s “working memory” and situational awareness. For example, if the student is in the early stage of a design (brainstorming concepts), the agent recognizes this context and shapes its responses appropriately (perhaps focusing on broad questions like “What are the main goals for your design?”). If the student is later in the process (refining details), the agent shifts context to more specific critique or technical guidance. The context module relies on parsing the conversation history and any external data (like the student’s sketch or notes). It may utilize the LLM in a reflective manner – e.g., summarizing what the student has done so far and inferring their intentions. By keeping track of context, the mentor avoids redundant advice and ensures continuity (e.g., “Earlier you mentioned focusing on natural lighting; let’s consider that now in your floor plan.”). Technically, this could be implemented via conversation embedding (summaries stored and re-injected) or a structured representation (like a JSON state that updates with key context variables).
Knowledge Synthesis & Domain Expert agent
In its role as a domain expert, the agent provides accurate and insightful information from the field of architecture. Knowledge synthesis refers to the agent’s ability to combine information from various sources – the built-in knowledge base, online resources (if allowed), and general training – to give the student a coherent answer. For instance, if the student asks about the sustainability of a certain material, the agent should retrieve facts about that material’s insulation properties, environmental impact, and perhaps reference an example project that used it. Unlike a standard AI which might dump a lengthy explanation, our mentor’s expert module is careful to tailor the knowledge to the student’s context (not too advanced or too basic) and to connect it to the current task (“Using cross-laminated timber could work well for the warehouse conversion, as it’s sustainable and can handle large spans – recall the example of the XYZ Community Hall which successfully used CLT for a similar open-space design.”). The agent might use an internal prompt specifically for this role, or even a separate smaller model trained on architecture data, to ensure authoritative and targeted knowledge delivery.
Socratic Dialogue & Questioning agent
A defining feature of the mentor is its capacity for Socratic dialogue, meaning it asks the student guided questions instead of simply providing solutions. This role is essentially the pedagogical strategist of the agent. It decides when to answer with a question, what question to ask, and how to respond to the student’s answers. For example, if a student asks, “What layout should I use for the community center?”, a Socratic response could be, “What functions do you envision in the community center, and how might they influence the layout?” This nudges the student to clarify goals before jumping to a solution. Designing this behavior may involve crafting a library of generic question templates tied to common design considerations (layout, lighting, accessibility, etc.), which the agent can instantiate based on context. We might also employ the LLM in a reflexive way: have it generate a question instead of an answer by modifying the prompt (like appending “Reply with a question that helps the student think deeper about the problem”). Ensuring the questions are not trivial is important – they should open up the design space or surface assumptions. The Socratic module also handles follow-up: if the student responds, the agent acknowledges and possibly asks another question or transitions to providing information if the student seems to need it. This dynamic is crucial to keep the student engaged in a back-and-forth that mirrors real tutorial dialogue.
Cognitive Enhancement agent
Beyond asking questions, the mentor might employ other strategies to stimulate cognition. One idea is metacognitive prompts – occasionally the mentor asks the student to reflect on their own process (e.g., “Can you summarize why you chose this design approach?”). Another is challenge scenarios: the agent might introduce a hypothetical change (“Imagine the budget was cut in half – how would you adapt your design?”) to encourage flexible thinking. These strategies act like exercises for the student’s mind, preventing them from becoming passive. The agent’s design includes triggers for these enhancements, perhaps time-based or event-based (if the student has been idle, or if they just accepted an AI suggestion without question, the mentor might inject a challenge). In terms of implementation, this could be a rule-based overlay or patterns recognized by the LLM (we could prompt the LLM to monitor the level of student initiative and respond accordingly). This role aligns with the thesis goal of purposeful cognitive development – it’s where the agent actively tries to develop the student’s skills, not just solve the problem.


Multi-agent or Multi-role Architecture
We are essentially attributing multiple “personas” or sub-agents within the AI mentor: the Context Keeper, the Domain Expert, the Socratic Tutor, the Cognitive Coach. We have flexibility in how to realize this. One approach is a single LLM instance with a composite prompt that instructs it to balance these roles (e.g., system prompt: “You are an architecture mentor [with these qualities]...” and then through few-shot examples demonstrate the behavior). Another approach is a multi-agent system: separate LLM calls or threads for each role that then coordinate. For example, a pipeline could be: the user’s query goes to a “Reasoner agent” that figures out what the user needs (context), then queries a “Knowledge agent” for facts if needed, then a “Tutor agent” formulates a response using both the question and facts. There has been research on such agent architectures that could inspire our design. The advantage of separation is clarity and possibly easier debugging (we can see which component might be failing). The disadvantage is complexity and increased computation. We will weigh these and perhaps prototype a simplified multi-agent loop if time permits.
Ensuring Explainability and Transparency
A critical aspect of the agent’s design is that it should maintain explainability – both internally (so developers/researchers understand decisions) and externally (so the student can understand the rationale behind advice). Internally, we might instrument the agent to output rationale in hidden logs (for research purposes) whenever it chooses to ask a question or give an answer. Externally, the agent can sometimes “think aloud” or show its reasoning in a student-friendly way. For example, the mentor might say, “Let’s consider step by step: usually, light and circulation are key in community centers. Have we addressed those? If not, maybe think about the window placement...”. This models a reasoning process for the student to learn from. Another approach is that when providing a piece of information, the agent could cite its source or precedent (which also combats anthropomorphism by reminding the student the knowledge is derived from human work or datapsychologytoday.com). For instance, “According to <i>Architectural Acoustics 2019 study</i>, open ceilings can double the noise level, which is why I asked about acoustics in your design.” Such explainability not only builds trust but also furthers learning, as the student can see the justification and perhaps follow references for deeper study. 
In designing these roles and their interplay, we align with cognitive science principles and intelligent tutoring system (ITS) literature that emphasize adaptive scaffolding and the zone of proximal development – giving help that is just enough to push the learner further without taking away the problem-solving opportunity. The ArchMentor agent is, in essence, an AI instantiation of a good studio mentor: part knowledgeable consultant, part coach, part devil’s advocate, and part cheerleader. This multi-role design will be carefully encoded and tested to ensure the agent behaves in a balanced, effective manner.
Real-time Feedback Loops (Adaptive Interaction)
Within a single mentoring session, the system will actively use feedback from the student to adapt its guidance. This can be seen as a micro-level feedback loop. For example, if the student seems confused (detected via repeated questions or explicit signals like “I don’t get it”), the mentor adjusts by switching from Socratic mode to a more direct explanatory mode for a bit, then maybe checks understanding again. Conversely, if the student is confidently making progress, the mentor might step back or pose a tougher challenge. Implementing this requires monitoring interaction signals: length of student’s responses, sentiment/tone (maybe via sentiment analysis on their messages), frequency of help requests, etc. The mentor will have thresholds or learned patterns for these signals. A simple approach is rule-based: e.g., “If student asks for help 3 times in a row, provide a more concrete hint now.” A more complex approach could train a model on past interaction data to predict the student’s state (engaged, frustrated, etc.) and choose an action. In any case, this adaptive loop ensures a personalized experience, much like a human tutor would modulate their strategy in response to a student’s cues.
Long-term Feedback (Learning from Cohort Data)
Beyond a single session, we establish a macro-level feedback loop using the data collected across many sessions and students. All interaction logs (anonymized) and outcomes will be analyzed to find patterns of what works well and what doesn’t. For instance, we might find that certain questions consistently lead to better student explanations, or that some hint caused many students to just copy the answer (meaning it was too leading). Using these insights, we can refine the mentor’s prompts, rules, or training. This is akin to reinforcement learning from human feedback (RLHF) except we may not implement a full RL algorithm within the thesis timeline; however, manual iteration guided by data is feasible. Additionally, if the mentor is deployed over a longer term, one could imagine an online learning system where it gradually adjusts its policy based on accumulated interactions (with safeguards). The thesis might not implement full online learning, but we will document how the design allows incorporating new knowledge – e.g., updating the knowledge base with new examples if we see students frequently ask about a certain new trend in architecture.


Explainability and Transparency to Users
As mentioned earlier, one of the mentor’s design goals is to avoid the “black box” issue that could further encourage blind trust. Therefore, throughout the interaction, the AI will strive to explain its reasoning or provide justifications for its suggestions. In practical terms, this means the mentor’s responses often include a “because” clause or a reference. For example, instead of just saying “Your design needs more natural light,” it might say “I suggest adding more windows because natural light is shown to improve user satisfaction in public spaces (see studies on school design)”. If the system retrieved a piece of information from the knowledge base, it can explicitly mention the source (or we can design a UI where the student can click to see “Why did the AI say this?” and it shows the source or reasoning path). Explainability also means admitting uncertainty: if the student asks something the AI is not sure about, the mentor should say so and possibly propose how to find out, rather than hallucinate an answer. This honesty builds trust and keeps the student mentally engaged (they might then join the AI in figuring it out). From an implementation standpoint, we will incorporate phrases in the prompt that encourage the model to show reasoning (like “show your reasoning step by step in a way the student can follow”). We may also utilize chain-of-thought prompting internally, where the model generates a hidden rationale, and then we extract a simplified version to present to the user.
Data Capture Architecture


Every interaction with the system will generate data that is invaluable for both research and potential future improvements. We will design the data capture with privacy and analysis in mind. Concretely, the system will log: 
Conversation transcripts (anonymized, replacing the student’s name with an ID, etc.),
Time-stamps for each message (to analyze pacing),
Any user actions like viewing a hint, uploading an image, etc.,
Mentor’s internal decisions (we might log the outputs of the context reasoning module, or which path it took in the dialogue policy, as metadata).
Performance outcomes like the final solution quality or test scores linked to the session.  This data will be stored securely (likely in an encrypted database or at least on a secure server accessible only to the research team). We will also implement export scripts to easily extract this data for analysis (e.g., in CSV format or JSON). Ensuring data integrity (no loss or mix-up of logs) is important for valid results.


Closing the Loop to Development
The feedback and data captured will not only be used for evaluation but can inform a final chapter on system improvement. For example, if the data reveals that students commonly face a particular challenge that the mentor doesn’t handle well, we can propose solutions (maybe adding a new prompt or expanding the knowledge base in that area). This reflective use of data closes the design research loop: our system was built on initial hypotheses (from MIT and others), tested, and now the results can lead to refined hypotheses or system tweaks. 
In summary, the AI mentor system is conceived as a learning system itself – learning from each interaction how to better help students. The emphasis on explainability ensures the student remains an active participant, hopefully internalizing not just architectural knowledge but also the reasoning process demonstrated by the mentor. The data capture and feedback loops ensure the thesis has a rich basis for analysis and that the system can continue to evolve even beyond the scope of this project.




THESIS APP HOW IT WORKS(INITIAL IDEA)
Multi-Agent AI Mentor System: Logic & Flow for Presentation1. SYSTEM OVERVIEW LOGICCore PhilosophyPrevent Cognitive Offloading: Never give direct answers; guide students to discover solutionsMulti-Agent Specialization: Each agent has a specific educational roleDomain Flexibility: Same system works across architecture, game design, industrial designAdaptive Learning: System adjusts based on student's understanding and engagementArchitecture PrinciplesModular Design: Independent agents can be added/removed easilyShared Context: All agents access the same student state and conversation historyOrchestrated Coordination: Central system decides which agents to activateExplainable Decisions: System can explain why it chose specific responses2. STUDENT INPUT CLASSIFICATION LOGICClassification CategoriesIF student asks factual question + shows high understanding → ROUTE TO: Knowledge Agent only IF student expresses confusion OR shows low understanding → ROUTE TO: Socratic Agent (primary) + Cognitive Agent (support) IF student shows overconfidence OR low engagement → ROUTE TO: Cognitive Agent (primary) + Socratic Agent (follow-up) IF student requests design feedback → ROUTE TO: All agents (Knowledge → Socratic → Cognitive) DEFAULT: Knowledge Agent + Socratic AgentContext Analysis ProcessParse student input for emotional indicators (confused, confident, frustrated)Analyze understanding level based on vocabulary and concept usageAssess engagement level from response length and enthusiasm markersDetermine cognitive load from complexity of current taskClassify interaction type (question, reflection, design submission, etc.)3. AGENT COORDINATION LOGICLangGraph Workflow Decision TreeENTRY POINT: Context Agent (always first) ↓ROUTER: Analyzes context and determines path ↓CONDITIONAL BRANCHES: ├── Knowledge Only Path ├── Socratic Focus Path ├── Cognitive Focus Path └── Multi-Agent Path ↓SYNTHESIZER: Combines all agent outputs ↓FINAL RESPONSE: Delivered to studentAgent Selection LogicSequential Processing: Agents process in priority order based on student needsContext Passing: Each agent receives full conversation context + previous agent outputsHandoff Decisions: Agents can recommend which agent should process nextParallel vs Sequential: Simple questions = one agent; complex problems = multiple agents4. KNOWLEDGE SYNTHESIS AGENT LOGICVector Retrieval ProcessReceive student query from orchestratorGenerate query embedding using sentence transformerSearch ChromaDB collection for current domain (architecture/game design/etc.)Retrieve top 5 relevant documents with similarity scoresFilter by relevance threshold (similarity > 0.6)Knowledge Synthesis LogicIF no relevant knowledge found: RETURN: "Let's explore this together. What do you think about..." IF high-quality knowledge found (similarity > 0.8): SYNTHESIZE: Combine sources + adapt to student level + cite sources IF medium-quality knowledge found (0.6 < similarity < 0.8): SYNTHESIZE: Use as supporting evidence + ask clarifying questions ALWAYS: Adapt complexity to student's understanding levelALWAYS: Include specific examples when helpfulALWAYS: End with open-ended question to maintain engagementDomain Adaptation LogicLoad domain-specific knowledge base from ChromaDB collectionUse domain-specific prompt templates (architecture vs game design vocabulary)Apply domain-specific evaluation criteria (spatial thinking vs systems thinking)Reference domain-specific examples and case studies5. SOCRATIC DIALOGUE AGENT LOGICQuestion Generation StrategySTUDENT UNDERSTANDING LEVEL:├── Low: Ask clarification questions ("What do you mean by...?")├── Medium: Ask exploratory questions ("What possibilities do you see...?")└── High: Ask analytical questions ("Why do you think this approach...?")STUDENT CONFIDENCE LEVEL:├── Uncertain: Provide supportive questioning + hints├── Confident: Continue with deeper exploration questions└── Overconfident: Challenge assumptions with "What if...?" scenariosSocratic Method ImplementationNever give direct answers - always respond with questions or hintsBuild on student's current understanding - use their vocabulary and conceptsGuide toward discovery - questions should lead to "aha!" momentsEscalate complexity gradually - start simple, build toward insightsEncourage reasoning out loud - "Can you walk me through your thinking?"Question Types by Learning GoalExploration: "What possibilities do you see?" "How might you approach this?"Clarification: "What do you mean by...?" "Can you be more specific?"Analysis: "Why do you think this works?" "What are the implications?"Synthesis: "How does this connect to...?" "What patterns do you notice?"6. COGNITIVE ENHANCEMENT AGENT LOGICCognitive State AssessmentENGAGEMENT INDICATORS:├── High: Long responses, questions, elaboration├── Medium: Basic responses, follows prompts└── Low: Short answers, passive acceptanceCOGNITIVE LOAD INDICATORS:├── Overloaded: Confused responses, requests for help├── Optimal: Thoughtful responses, some struggle└── Underloaded: Quick answers, seems boredMETACOGNITIVE AWARENESS:├── High: Reflects on process, questions own assumptions├── Medium: Some self-awareness, limited reflection └── Low: No process awareness, accepts without questionEnhancement Strategy SelectionIF student shows passivity OR low engagement: APPLY: Challenge scenario ("What if budget was cut 50%?") IF student needs reflection OR medium engagement: APPLY: Metacognitive prompt ("Explain your thinking process") IF student shows high engagement OR overconfidence: APPLY: Perspective shift ("How would a child experience this?") IF student demonstrates good understanding: APPLY: Advanced challenge ("Consider the opposite approach")Cognitive Challenge TypesConstraint Changes: Modify budget, timeline, space, materialsPerspective Shifts: Different user groups, time periods, contextsAlternative Exploration: Opposite approaches, different methodsMetacognitive Prompts: Reflect on thinking, question assumptions7. RESPONSE SYNTHESIS LOGICMulti-Agent Response CombinationPRIORITY ORDER for final response:1. Socratic Agent response (if asking questions)2. Cognitive Agent enhancement (if providing challenges) 3. Knowledge Agent synthesis (if providing information)4. Context Agent insights (for continuity)COMBINATION RULES:├── IF Socratic question exists: Use as primary response├── IF Cognitive challenge exists: Integrate with Socratic or use standalone├── IF Knowledge content exists: Weave into questions/challenges or provide separately└── ALWAYS: Maintain educational flow and avoid information dumpingConfidence Score CalculationKnowledge Confidence: Based on similarity scores from vector retrievalSocratic Confidence: Based on question appropriateness to student levelCognitive Confidence: Based on challenge relevance to student stateFinal Confidence: Weighted average prioritizing active learning componentsResponse Quality AssuranceEducational Value Check: Does response promote learning?Cognitive Load Check: Appropriate difficulty for student level?Engagement Check: Will this maintain student interest?Coherence Check: Does response flow naturally from conversation?8. DOMAIN FLEXIBILITY LOGICDomain Switching MechanismWHEN switching from Architecture to Game Design:1. LOAD new ChromaDB collection (game_design_knowledge)2. UPDATE agent prompt templates (architectural → game design vocabulary)3. CHANGE evaluation criteria (spatial thinking → systems thinking)4. MODIFY question templates (building design → player experience)5. ADAPT challenge scenarios (space constraints → mechanic constraints)Knowledge Base AbstractionStandardized Document Structure: All domains use same metadata schemaUniversal Embedding Model: Same sentence transformer across domainsConfigurable Prompts: JSON templates for domain-specific languageFlexible Evaluation: Domain-specific quality metrics and rubricsDomain Configuration ComponentsKnowledge Sources: Domain-specific documents and case studiesVocabulary Maps: Key terms and concepts for each fieldQuestion Templates: Domain-appropriate Socratic questionsChallenge Scenarios: Field-specific cognitive challengesEvaluation Rubrics: Domain-specific success criteria9. LEARNING LOOP & ADAPTATION LOGICReal-Time Adaptation (Within Session)MONITOR student responses for:├── Confusion signals → Increase support, simplify questions├── Boredom signals → Increase challenge, add complexity├── Frustration signals → Provide encouragement, break down problems└── Engagement signals → Maintain current approach, explore deeperADJUST agent selection based on:├── Response quality → More/less cognitive challenge├── Understanding progression → Advance/review concepts ├── Engagement level → Modify interaction style└── Confidence changes → Adapt questioning approachLong-Term Learning (Across Sessions)Student Profile Updates: Track mastery of concepts over timePattern Recognition: Identify recurring learning challengesAdaptive Questioning: Personalize question difficulty to student growthProgress Tracking: Monitor skill development across sessionsSystem Self-Improvement LogicInteraction Analysis: Which agent combinations work best?Response Quality Tracking: What generates best learning outcomes?Student Satisfaction Metrics: Engagement and satisfaction patternsDomain Performance Comparison: How well does system adapt across fields?



PECHA KUCHA STYLE BRIEF OVERVIEW OF THE PROJECT
PechaKucha Script


Slide 1: Intro (20 seconds)


Good Morning, we are Biel Pitman, Mahnoor Fatima and Seda Soylu and today we’re going to introduce you to Mentor, a Multi-agent AI System in charge of ensuring Purposeful Cognitive Development (in Architecture) 


________________





Slide 2: The Problem - Brain Damage (20 seconds)
"LLM users are unknowingly damaging their brains. A groundbreaking MIT study revealed that AI users experienced a shocking 55% reduction in neural connectivity. Their thinking pathways literally shut down, and the damage persisted even when students stopped using AI. We’re creating a generation of cognitively dependent designers."
________________




Slide 3: The Stakes (20 seconds)
"74% of new architecture graduates don't feel confident in their independent design skills. With AI adoption jumping from 41% to 59% of firms in just one year, we're facing an educational crisis. Students are outsourcing their creativity to machines, losing the very cognitive muscles that make great architects."
________________




Slide 4: The Breakthrough (20 seconds)
"But there's hope. The MIT study found one crucial protection: students who established natural thinking patterns FIRST maintained strong brain activity even when later using AI. Turns out the sequence matters. Brain-first, AI-later. This discovery changes everything about how we should design AI tools for education."
________________




Slide 5: Our Mission (20 seconds)
"Which is why we’re developing Mentor, a multimodal AI system that doesn't replace thinking, it amplifies it. Instead of giving answers, it asks the right questions. Instead of cognitive offloading, it creates cognitive scaffolding. Instead of making students dependent, it makes them more independent."
________________




Slide 6: The Three-Phase Journey (20 seconds)
"Mentor guides students through three distinct phases: Ideation for conceptual spatial reasoning, Visualization for 2D analysis and computer vision processing, and Materialization for 3D spatial analysis. Each phase builds cognitive muscles progressively, preventing the neural shutdown we see with traditional AI tools."
________________




Slide 7: Four Intelligent Agents (20 seconds)
"Four specialized AI agents work in harmony: The Context Reasoning Agent questions spatial relationships, the Knowledge Synthesis Agent connects theory to practice, the Socratic Dialogue Agent facilitates critical thinking, and the Metacognitive Agent tracks learning progression. Together, they create a complete cognitive enhancement ecosystem."
________________




Slide 8: Real Spatial Intelligence (20 seconds)
"Unlike generic AI that talks about design, Mentor understands spatial relationships: proportion, circulation, light and orientation, adjacency and hierarchy. It analyzes sketches, processes 3D models, and provides spatially-aware feedback that builds genuine architectural intelligence in students."
________________




Slide 9: The Socratic Method (20 seconds)
"When a student asks 'What materials should I use?', generic AI lists options. While Mentor asks: 'What story do you want this space to tell? How do people move through it? What light qualities do you envision?' It transforms every interaction into a learning opportunity."
________________




Slide 10: Measuring Success (20 seconds)
"We've developed six breakthrough metrics: Cognitive Offloading Prevention, Deep Thinking Engagement, Scaffolding Effectiveness, Knowledge Integration, Learning Progression, and Metacognitive Awareness. These aren't just scores, they're real-time measures of cognitive development that adapt the system's behavior."
________________




Slide 11: The Benchmark Revolution (20 seconds)
"Our comprehensive testing compares Mentor against standard LLM tools using rigorous evaluation criteria. Early results show Mentor leads in comprehension and cognitive load management, while traditional AI excels only in knowledge retention, exactly what we'd expect from tools designed for different purposes."
________________




Slide 12: Test Challenge (20 seconds)
"To test it, we’ve engineered a challenge in which students will be split into 3 groups (Mentor, Standard LLM users and a Control group without AI assistance). After our initial tests are completed, we’ll ask our MaCAD colleague students to help us test the application."
________________




Slide 13: Results Analysis (20 seconds)
"We’ll track every design decision using advanced analysis systems, mapping how ideas connect and evolve. Without biometric tracking systems like the ones used by MIT, we’ll still use research-backed methods to analyze results in order to perform consistent cross-platform evaluation. 
________________




Slide 14: Vision Processing (20 seconds)
"Students can upload sketches and Mentor sees what they see (and what they miss). Computer vision analysis combined with architectural knowledge creates feedback that's spatially intelligent. It's like having a master Architect review your drawings, but one that never gives away the answer."
________________




Slide 15: 3D Spatial Analysis (20 seconds)
"In the materialization phase, students could navigate through their designs while Mentor provides real-time spatial analysis. Proportion relationships, circulation patterns, and environmental responses become tangible, learnable concepts rather than abstract theories."
________________




Slide 16: Technical Innovation (20 seconds)
"Our Graph Machine Learning architecture treats every interaction as connected knowledge. Unlike linear AI conversations, Mentor builds persistent understanding of each student's spatial reasoning development. It learns how you think, not just what you ask."
________________




Slide 17: Cognitive Protection (20 seconds)
"Real-time monitoring detects when students slip into cognitive offloading patterns. The system automatically adjusts asking deeper questions, requiring more reflection, nudging toward independent thinking. It's like having a cognitive immune system that prevents AI dependency."
________________




Slide 18: Research Impact (20 seconds)
"This isn't just a tool, it's a new model for AI in education. We hope that our research methodology, benchmarking framework, and cognitive metrics could serve as blueprints for developing AI systems that enhance rather than replace human intelligence even beyond creative disciplines."
________________




Slide 19: Validation Strategy (20 seconds)
"Controlled studies with architecture students using pre/post assessments, expert evaluations, and cross-platform performance measures. We're not just claiming cognitive benefits, we're proving them through rigorous scientific methodology that could revolutionize how we think about AI in education."
________________




Slide 20: The Future of Learning (20 seconds)
"Imagine AI tools that make you smarter, not lazier. That builds expertise, not dependence. That amplifies human creativity instead of replacing it. We're not just training better architects, we’re helping build relationships between human and artificial intelligence, with Mentor we’re helping build the future of learning through collaborative intelligence."
Thank you