
## AI-Powered Architectural Education with Cognitive Enhancement

A comprehensive thesis project for MaCAD that combines cutting-edge computer vision (GPT-4 Vision + SAM), multi-agent AI systems, and cognitive benchmarking with linkography integration to revolutionize architectural education through preventing cognitive offloading and enhancing critical thinking.

---

## 🌟 Key Features

### 1. **Computer Vision Analysis**
- **GPT-4 Vision**: Analyzes architectural drawings for design elements, composition, and principles
- **SAM Integration**: Precise segmentation of architectural elements
- **Real-time Feedback**: Instant visual analysis of uploaded sketches and drawings

### 2. **Multi-Agent AI System**
- **Socratic Tutor**: Guides learning through questions, never providing direct answers
- **Domain Expert**: Offers specialized architectural knowledge when needed
- **Cognitive Enhancement Agent**: Monitors and prevents cognitive offloading
- **Context Agent**: Maintains conversation continuity and learning progression
- **Analysis Agent**: Processes visual artifacts and generates architectural insights

### 3. **Cognitive Benchmarking**
- **Six Core Metrics**: COP, DTE, SE, KI, LP, MA for comprehensive assessment
- **Graph ML Analysis**: Uses Graph Neural Networks for pattern recognition
- **Proficiency Classification**: Categorizes users from beginner to expert
- **Interactive Dashboards**: Real-time visualization of learning progress

### 4. **Linkography Integration** 🆕
- **Design Process Analysis**: Implements Gabriela Goldschmidt's linkography methodology
- **Real-time Linkograph Generation**: Visualizes design thinking patterns as they emerge
- **Fuzzy Linkography**: Uses semantic embeddings (all-MiniLM-L6-v2) for intelligent link detection
- **Pattern Recognition**: Identifies cognitive overload, design fixation, and creative breakthroughs
- **Interactive Visualizations**: PyVis-powered interactive linkographs in the dashboard

---

## 🚀 Quick Start

### Basic Setup (Without SAM)

```bash
# 1. Create virtual environment
python -m venv mega_env
mega_env\Scripts\activate  # Windows
source mega_env/bin/activate  # Mac/Linux

# 2. Install core dependencies
pip install -r requirements.txt

# 3. Set OpenAI API key
echo "OPENAI_API_KEY=your_key_here" > .env

# 4. Run the application
streamlit run mega_architectural_mentor.py
```

### Full Setup (With SAM + All Features)

```bash
# 1. Create virtual environment
python -m venv mega_env
mega_env\Scripts\activate  # Windows

# 2. Install all dependencies
pip install -r requirements_mega.txt

# 3. Install benchmarking dependencies (includes linkography)
pip install -r benchmarking/requirements_benchmarking.txt

# 4. Set OpenAI API key
echo "OPENAI_API_KEY=your_key_here" > .env

# 5. Run the application
streamlit run mega_architectural_mentor.py
```

---

## 📊 Cognitive Benchmarking & Linkography

### Running Analysis

```bash
# Full benchmarking pipeline
python benchmarking/run_benchmarking.py

# Generate test data (if needed)
python benchmarking/generate_test_data.py

# Launch interactive dashboard
python benchmarking/launch_dashboard.py

# Linkography-specific analysis
python benchmarking/linkography_analyzer.py
```

### Key Metrics

- **Cognitive Offloading Prevention (COP)**: >70% target
- **Deep Thinking Engagement (DTE)**: >60% target
- **Scaffolding Effectiveness (SE)**: Adaptive learning support
- **Knowledge Integration (KI)**: Cross-domain synthesis
- **Learning Progression (LP)**: Skill development tracking
- **Metacognitive Awareness (MA)**: Self-reflection capabilities

### Linkography Metrics

- **Link Density**: Measure of cognitive engagement intensity
- **Critical Moves**: Identification of key design decisions
- **Phase Balance**: Distribution across ideation/visualization/materialization
- **Pattern Detection**: Automated recognition of cognitive states

---

## 🏛️ Architecture

```
mega-architectural-mentor/
├── mega_architectural_mentor.py    # Main unified application
├── thesis-agents/                  # Multi-agent system
│   ├── agents/                     # Individual AI agents
│   ├── orchestration/              # LangGraph orchestrator
│   └── data_collection/            # Interaction logging
├── src/core/detection/             # Computer vision modules
│   ├── vision/                     # GPT-4V integration
│   └── sam2_module_fixed.py        # SAM integration
├── benchmarking/                   # Cognitive assessment
│   ├── graph_ml_benchmarking.py   # GNN analysis
│   ├── linkography_*.py            # Linkography modules
│   └── benchmark_dashboard.py      # Interactive dashboard
└── knowledge_base/                 # Architectural knowledge
    └── downloaded_pdfs/            # 40+ architecture texts
```

---

## 📈 Data Collection & Analysis

### Automatic Logging
- Every interaction is automatically logged to CSV files
- Session data includes timestamps, metrics, and full conversation history
- Export button in sidebar for manual data export

### Data Format
```
thesis_data/
├── interactions_[session_id].csv   # Detailed interaction logs
├── full_log_[session_id].json     # Complete session data
└── session_summary_[session_id].json  # Summary metrics
```

---

## 🧪 Testing & Validation

### B-Test Framework
- Comprehensive testing suite for architectural education scenarios
- Validates cognitive enhancement effectiveness
- Measures improvement over traditional tutoring methods

### Performance Requirements
- Real-time response: <100ms for linkograph updates
- Scalability: 100+ concurrent sessions
- Accuracy: >80% correlation with human assessments

---

## 🔧 Configuration

### Environment Variables (.env)
```
OPENAI_API_KEY=your_openai_api_key
SAM_DEVICE=cpu  # or cuda for GPU
```

### Config Files
- `config.json`: Main application settings
- `benchmarking/config/`: Benchmarking-specific settings

---

## 📚 Research Components

### Thesis Objectives
1. **Prevent Cognitive Offloading**: Encourage deep thinking over quick answers
2. **Enhance Critical Thinking**: Socratic method implementation
3. **Track Learning Progress**: Real-time cognitive assessment
4. **Visualize Design Thinking**: Linkography integration

### Publications & References
- Based on Gabriela Goldschmidt's Linkography methodology
- Implements cognitive load theory principles
- Follows educational scaffolding best practices

---

## 🤝 Contributing

This is an active thesis project. For questions or collaboration:
- Review `CLAUDE.md` for detailed development guidelines
- Check `thesis_docs/` for research documentation
- Run tests before submitting changes

---

## 📄 License

This project is part of the MaCAD (Master in Advanced Computation for Architecture & Design) thesis program.

---

**Built with ❤️ for the future of architectural education**
=======
A sophisticated AI-powered architectural tutoring system that combines multi-agent learning, computer vision, and cognitive benchmarking to provide personalized architectural guidance.

## 🎯 Overview

The MEGA Architectural Mentor is a comprehensive AI system designed to help architecture students and professionals develop their design thinking through:

- **Multi-Agent Tutoring**: Sophisticated Socratic questioning and domain expertise
- **Computer Vision Analysis**: GPT Vision + SAM segmentation for architectural drawings
- **Cognitive Benchmarking**: Graph ML-based assessment of learning effectiveness
- **Flexible Input Modes**: Text-only, image-only, or combined analysis
- **Real-time Learning Assessment**: Dynamic cognitive analysis and skill tracking

## 🚀 Key Features

### 🤖 Multi-Agent System
- **Socratic Tutor Agent**: Guides critical thinking through strategic questioning
- **Domain Expert Agent**: Provides architectural knowledge and technical guidance
- **Cognitive Enhancement Agent**: Challenges assumptions and promotes deeper thinking
- **Context Agent**: Analyzes student state and conversation progression
- **Analysis Agent**: Performs visual and textual analysis of projects

### 🖼️ Computer Vision Integration
- **GPT Vision Analysis**: Comprehensive architectural drawing interpretation
- **SAM2 Segmentation**: Precise spatial element detection and segmentation
- **Design Insights**: Automated identification of strengths, issues, and suggestions
- **Visual Feedback**: Interactive visualizations of analysis results

### 📊 Cognitive Benchmarking
- **Graph ML Analysis**: Advanced pattern recognition in learning interactions
- **Proficiency Classification**: ML-based skill level assessment (Beginner → Expert)
- **Effectiveness Metrics**: Comparison with traditional tutoring methods
- **Interactive Dashboard**: Comprehensive visualization of learning progress

### 🎛️ Flexible Input Modes
- **Text Only**: Project descriptions without images
- **Image + Text**: Combined visual and textual analysis
- **Image Only**: Pure visual analysis of architectural drawings
- **Template Prompts**: Quick-start templates for common project types

### 🔄 Real-time Learning Assessment
- **Dynamic Cognitive Analysis**: Real-time assessment based on latest interactions
- **Skill Level Tracking**: Continuous monitoring of learning progression
- **Response Type Analysis**: Understanding of educational strategies employed
- **Agent Effectiveness**: Tracking which agents are most helpful

## 🏗️ System Architecture

```
MEGA Architectural Mentor
├── 🎯 Main Application (mega_architectural_mentor.py)
├── 🤖 Multi-Agent System (thesis-agents/)
│   ├── Analysis Agent
│   ├── Socratic Tutor Agent
│   ├── Domain Expert Agent
│   ├── Cognitive Enhancement Agent
│   └── Context Agent
├── 🖼️ Computer Vision (vision/)
│   ├── GPT Vision Analysis
│   └── SAM2 Segmentation
├── 📊 Benchmarking System (benchmarking/)
│   ├── Graph ML Analysis
│   ├── Evaluation Metrics
│   ├── Visualization Tools
│   └── Interactive Dashboard
└── 📚 Knowledge Base (knowledge_base/)
    ├── Vector Database
    └── Document Storage
```

## 🛠️ Installation

### Prerequisites
- Python 3.8+
- OpenAI API key
- CUDA-compatible GPU (optional, for SAM2)

### Setup Instructions

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd macad-thesis-25
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements_mega.txt
   ```

3. **Set up environment variables**
   ```bash
   # Create .env file
   echo "OPENAI_API_KEY=your_api_key_here" > .env
   ```

4. **Install SAM2 (optional)**
   ```bash
   # For SAM2 segmentation capabilities
   pip install segment-anything-2
   ```

## 🚀 Usage

### Starting the Application

```bash
streamlit run mega_architectural_mentor.py
```

The application will open at `http://localhost:8501`

### Basic Workflow

1. **Select Input Mode**
   - Choose between Text Only, Image + Text, or Image Only
   - Enable/disable SAM segmentation analysis

2. **Choose Mentor Type**
   - **Socratic Agent**: Multi-agent system with sophisticated questioning
   - **Raw GPT**: Direct GPT responses for comparison

3. **Select Template (Optional)**
   - Choose from pre-built project templates
   - Or write your own project description

4. **Set Skill Level**
   - Beginner, Intermediate, or Advanced
   - Helps tailor the mentoring approach

5. **Upload Content**
   - Upload architectural drawings (if using image modes)
   - Describe your project goals and constraints

6. **Start Analysis**
   - Click "Start Analysis" to begin the comprehensive evaluation
   - View results and begin interactive conversation

### Advanced Features

#### Template Design Prompts
- **🏢 Sustainable Office Building**: Complete brief for tech company office
- **🏫 Community Learning Center**: Comprehensive educational hub project

#### Benchmarking Dashboard
- Access via sidebar button
- View cognitive analysis results
- Track learning progression
- Compare with baseline methods

## 📊 Benchmarking System

### Running Cognitive Analysis

1. **Collect Data**: Use the main application normally
2. **Run Benchmarking**: Click "🔬 Run Benchmarking" in sidebar
3. **View Results**: Click "📈 View Dashboard" for interactive analysis

### Dashboard Features

- **Key Metrics Overview**: Total sessions, improvement rates
- **Proficiency Analysis**: Skill level distribution and characteristics
- **Cognitive Pattern Analysis**: Multi-dimensional assessment
- **Learning Progression**: Temporal analysis of improvement
- **Agent Effectiveness**: Coordination and response analysis

### Data Requirements

- **Basic Analysis**: 1+ sessions
- **Clustering & Benchmarks**: 3+ sessions recommended
- **Proficiency Classifier**: 5+ sessions required
- **Optimal Results**: 10+ sessions with varied interactions

## 🧠 Multi-Agent System Details

### Agent Roles

#### Analysis Agent
- **Purpose**: Initial project analysis and cognitive flag generation
- **Capabilities**: 
  - Building type detection
  - Cognitive gap identification
  - Visual analysis integration
  - Skill assessment

#### Socratic Tutor Agent
- **Purpose**: Guide critical thinking through strategic questioning
- **Capabilities**:
  - Student state analysis (confidence, understanding, engagement)
  - Conversation progression tracking
  - Adaptive response strategies
  - Clarifying, supportive, and challenging guidance

#### Domain Expert Agent
- **Purpose**: Provide architectural knowledge and technical guidance
- **Capabilities**:
  - Technical knowledge provision
  - Example generation
  - Best practices sharing
  - Contextual advice

#### Cognitive Enhancement Agent
- **Purpose**: Challenge assumptions and promote deeper thinking
- **Capabilities**:
  - Assumption identification
  - Alternative perspective generation
  - Critical thinking promotion
  - Creative problem-solving

#### Context Agent
- **Purpose**: Analyze conversation context and student state
- **Capabilities**:
  - Interaction type classification
  - Confidence level assessment
  - Engagement monitoring
  - Routing recommendations

## 🖼️ Computer Vision Features

### GPT Vision Analysis
- **Spatial Elements**: Detection of rooms, corridors, structural elements
- **Circulation Analysis**: Primary and secondary path identification
- **Design Insights**: Strengths, issues, and improvement suggestions
- **Contextual Understanding**: Integration with architectural principles

### SAM2 Segmentation
- **Precise Segmentation**: Pixel-perfect element separation
- **Spatial Relationships**: Understanding of element connections
- **Quantitative Analysis**: Area calculations and proportions
- **Visual Feedback**: Interactive segmentation overlays

## 📈 Learning Assessment

### Dynamic Cognitive Analysis
- **Real-time Updates**: Analysis based on latest interactions
- **Response Type Tracking**: Understanding of educational strategies
- **Learning Focus Identification**: Current educational priorities
- **Progress Monitoring**: Continuous skill development tracking

### Skill Assessment
- **Confidence Level**: Student self-assurance assessment
- **Understanding Level**: Comprehension depth evaluation
- **Engagement Level**: Participation and interest measurement
- **Agent Usage**: Tracking of most effective mentoring approaches

## 🔧 Configuration

### Environment Variables
```bash
OPENAI_API_KEY=your_openai_api_key
```

### Session State Management
The application uses Streamlit session state to maintain:
- User preferences and settings
- Conversation history
- Analysis results
- Learning progress

### Customization Options
- **CSS Styling**: Dark theme with custom styling
- **Agent Parameters**: Adjustable response characteristics
- **Benchmarking Settings**: Configurable analysis parameters
- **Visualization Options**: Customizable dashboard appearance

## 📁 Project Structure

```
macad-thesis-25/
├── mega_architectural_mentor.py    # Main application
├── requirements_mega.txt           # Dependencies
├── CLAUDE.md                       # Development documentation
├── thesis-agents/                  # Multi-agent system
│   ├── agents/                     # Individual agents
│   ├── orchestration/              # LangGraph orchestrator
│   ├── vision/                     # Computer vision components
│   └── data_collection/            # Interaction logging
├── benchmarking/                   # Cognitive analysis system
│   ├── benchmark_dashboard.py      # Interactive dashboard
│   ├── graph_ml_benchmarking.py    # Graph ML analysis
│   ├── evaluation_metrics.py       # Assessment metrics
│   └── results/                    # Analysis outputs
├── src/core/detection/             # SAM2 integration
├── segment-anything-2/             # SAM2 implementation
├── knowledge_base/                 # Document storage
├── thesis_data/                    # User interaction data
└── lib/                           # External libraries
```

## 🐛 Troubleshooting

### Common Issues

1. **SAM2 Import Error**
   ```bash
   pip install segment-anything-2
   ```

2. **OpenAI API Error**
   - Verify API key in environment variables
   - Check API quota and billing

3. **Memory Issues**
   - Reduce image resolution
   - Disable SAM analysis for large images

4. **Benchmarking Dashboard Not Loading**
   - Ensure sufficient interaction data (3+ sessions)
   - Check file permissions in benchmarking/results/

### Performance Optimization

- **GPU Acceleration**: Enable CUDA for SAM2 processing
- **Image Optimization**: Compress images before upload
- **Session Management**: Clear session state periodically
- **Memory Management**: Monitor RAM usage during analysis

## 🔮 Future Enhancements

### Planned Features
- **Multi-language Support**: International architectural terminology
- **Advanced Visualizations**: 3D model analysis and feedback
- **Collaborative Learning**: Multi-user session support
- **Mobile Interface**: Responsive design for mobile devices
- **API Integration**: RESTful API for external applications

### Research Directions
- **Advanced Graph ML**: Enhanced cognitive pattern recognition
- **Personalized Learning**: Adaptive curriculum generation
- **Cross-cultural Analysis**: Cultural context in architectural design
- **Sustainability Focus**: Environmental impact assessment

## 📚 Academic Context

This system is designed for architectural education research, specifically investigating:
- **Cognitive Development**: How AI tutoring affects design thinking
- **Multi-Agent Learning**: Effectiveness of specialized agent coordination
- **Computer Vision in Education**: Visual analysis for architectural feedback
- **Benchmarking Methodologies**: Scientific evaluation of AI tutoring systems

## 🤝 Contributing

### Development Guidelines
1. **Code Style**: Follow PEP 8 standards
2. **Documentation**: Update relevant documentation
3. **Testing**: Add tests for new features
4. **Benchmarking**: Ensure new features don't degrade performance

### Research Collaboration
- **Data Sharing**: Anonymized interaction data for research
- **Methodology**: Collaborative development of assessment metrics
- **Publications**: Joint research on AI in architectural education

## 📄 License

[Add your license information here]

## 🙏 Acknowledgments

- **OpenAI**: GPT-4o and Vision API
- **Meta AI**: Segment Anything Model 2
- **Streamlit**: Web application framework
- **LangGraph**: Multi-agent orchestration
- **Academic Community**: Research and feedback

---

**🏗️ MEGA Architectural Mentor** - Advancing architectural education through AI-powered cognitive development and multi-agent learning systems. 

